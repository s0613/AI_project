{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import wiener\n",
    "import torch\n",
    "import warnings\n",
    "import pickle\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Trying to estimate tuning from empty frequency set.\")\n",
    "\n",
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    ROOT_FOLDER = './'\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 32\n",
    "    N_EPOCHS = 25\n",
    "    LR = 3e-4\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CONFIG.SEED)\n",
    "\n",
    "def pad_or_truncate(audio, target_length):\n",
    "    if len(audio) > target_length:\n",
    "        return audio[:target_length]\n",
    "    else:\n",
    "        return np.pad(audio, (0, target_length - len(audio)), mode='reflect')\n",
    "\n",
    "def preemphasis(signal, coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "def noise_reduction(signal):\n",
    "    filtered_signal = wiener(signal)\n",
    "    return filtered_signal / np.sqrt(np.mean(filtered_signal ** 2))  # RMS 정규화\n",
    "\n",
    "def energy_vad(signal, frame_length=2048, hop_length=512, threshold=0.1):\n",
    "    energy = librosa.feature.rms(y=signal, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    frames = np.nonzero(energy > threshold)[0]\n",
    "    vad_signal = []\n",
    "    for frame in frames:\n",
    "        start = frame * hop_length\n",
    "        end = start + frame_length\n",
    "        vad_signal.extend(signal[start:end])\n",
    "    return np.array(vad_signal)\n",
    "\n",
    "def mix_signals(signal1, signal2, sr):\n",
    "    max_length = max(len(signal1), len(signal2))\n",
    "    signal1 = np.pad(signal1, (0, max_length - len(signal1)), mode='constant')\n",
    "    signal2 = np.pad(signal2, (0, max_length - len(signal2)), mode='constant')\n",
    "    mixed_signal = signal1 + signal2\n",
    "    return mixed_signal / np.max(np.abs(mixed_signal)), sr  # 정규화\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    return np.concatenate([\n",
    "        np.mean(features, axis=0),\n",
    "        np.std(features, axis=0),\n",
    "        np.max(features, axis=0),\n",
    "        np.min(features, axis=0),\n",
    "        np.median(features, axis=0),\n",
    "        np.percentile(features, 25, axis=0),\n",
    "        np.percentile(features, 75, axis=0),\n",
    "        skew(features, axis=0),\n",
    "        kurtosis(features, axis=0)\n",
    "    ])\n",
    "\n",
    "def extract_features(audio_path, target_length=5*CONFIG.SR):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=CONFIG.SR)\n",
    "        sr = CONFIG.SR\n",
    "\n",
    "        y = preemphasis(y)\n",
    "        y = noise_reduction(y)\n",
    "\n",
    "        vad_signal = energy_vad(y)\n",
    "\n",
    "        if len(vad_signal) == 0:\n",
    "            vad_signal = y\n",
    "\n",
    "        vad_signal = pad_or_truncate(vad_signal, target_length)\n",
    "        mfcc = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc2 = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=2 * CONFIG.N_MFCC)\n",
    "        stft = np.abs(librosa.stft(vad_signal))\n",
    "        chroma = librosa.feature.chroma_stft(y=vad_signal, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=vad_signal, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(vad_signal), sr=sr)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        return np.concatenate([\n",
    "            calculate_statistics(mfcc.T),\n",
    "            calculate_statistics(mfcc2.T),\n",
    "            calculate_statistics(stft.T),\n",
    "            calculate_statistics(chroma.T),\n",
    "            calculate_statistics(spectral_contrast.T),\n",
    "            calculate_statistics(tonnetz.T),\n",
    "            calculate_statistics(mfcc_delta.T),\n",
    "            calculate_statistics(mfcc_delta2.T)\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return np.zeros((CONFIG.N_MFCC * 9 + 2 * CONFIG.N_MFCC * 9 + 1025 * 9 + 12 * 9 + 7 * 9 + 6 * 9 + CONFIG.N_MFCC * 9 + CONFIG.N_MFCC * 9))\n",
    "\n",
    "def save_features(features, labels, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((features, labels if labels is not None else []), f)\n",
    "\n",
    "os.makedirs(os.path.join(CONFIG.ROOT_FOLDER, 'newFolder'), exist_ok=True)\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(CONFIG.ROOT_FOLDER, 'train.csv'))\n",
    "\n",
    "train_audio_paths = train_df.iloc[:, 1].tolist()\n",
    "train_audio_paths = [os.path.join(CONFIG.ROOT_FOLDER, path) for path in train_audio_paths]\n",
    "train_labels = [1 if label == 'real' else 0 for label in train_df['label']]\n",
    "train_features = [extract_features(path) for path in tqdm(train_audio_paths, dynamic_ncols=True, position=0, leave=True)]\n",
    "\n",
    "real_voices = [path for path, label in zip(train_audio_paths, train_labels) if label == 1]\n",
    "fake_voices = [path for path, label in zip(train_audio_paths, train_labels) if label == 0]\n",
    "\n",
    "mixed_audio_paths = []\n",
    "for real_voice, fake_voice in zip(real_voices, fake_voices):\n",
    "    try:\n",
    "        y_real, sr_real = librosa.load(real_voice, sr=CONFIG.SR)\n",
    "        y_fake, sr_fake = librosa.load(fake_voice, sr=CONFIG.SR)\n",
    "        mixed_signal, sr = mix_signals(y_real, y_fake, sr_real)\n",
    "        mixed_audio_path = os.path.join(CONFIG.ROOT_FOLDER, f'newFolder/mixed_{os.path.basename(real_voice)}')\n",
    "        sf.write(mixed_audio_path, mixed_signal, sr)\n",
    "        mixed_audio_paths.append(mixed_audio_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {real_voice} and {fake_voice}: {e}\")\n",
    "\n",
    "mixed_features = [extract_features(path) for path in tqdm(mixed_audio_paths, dynamic_ncols=True, position=0, leave=True)]\n",
    "mixed_labels = [1] * len(mixed_features)\n",
    "\n",
    "train_features.extend(mixed_features)\n",
    "train_labels.extend(mixed_labels)\n",
    "\n",
    "save_features(train_features, train_labels, os.path.join(CONFIG.ROOT_FOLDER, 'newFolder/train_features.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9783\n",
      "ROC AUC Score (Fake): 0.9980\n",
      "ROC AUC Score (Real): 0.9980\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.signal import wiener\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "class Config:\n",
    "    N_FEATURES = 9\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "# 데이터 불러오기\n",
    "with open('./newFolder/train_features.pkl', 'rb') as f:\n",
    "    features, labels = pickle.load(f)\n",
    "\n",
    "# NaN 값을 평균값으로 대체\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features = imputer.fit_transform(features)\n",
    "\n",
    "# 다중 레이블로 변환\n",
    "labels = np.array(labels)\n",
    "y = np.column_stack([(labels == 0).astype(int), (labels == 1).astype(int)])\n",
    "\n",
    "# 데이터셋을 학습용과 테스트용으로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=CONFIG.SEED)\n",
    "\n",
    "# 다중 레이블 분류를 위한 랜덤 포레스트 모델 생성\n",
    "rf_model = MultiOutputClassifier(RandomForestClassifier(random_state=CONFIG.SEED))\n",
    "\n",
    "# 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc_fake = roc_auc_score(y_test[:, 0], [prob[1] for prob in y_pred_proba[0]])\n",
    "roc_auc_real = roc_auc_score(y_test[:, 1], [prob[1] for prob in y_pred_proba[1]])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC AUC Score (Fake): {roc_auc_fake:.4f}\")\n",
    "print(f\"ROC AUC Score (Real): {roc_auc_real:.4f}\")\n",
    "\n",
    "# 모델 저장\n",
    "with open('./newFolder/rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from test files:   0%|          | 6/50000 [00:03<7:40:08,  1.81it/s]/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/scipy/signal/_signaltools.py:1629: RuntimeWarning: divide by zero encountered in divide\n",
      "  res *= (1 - noise / lVar)\n",
      "/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/scipy/signal/_signaltools.py:1629: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n",
      "Extracting features from test files:   0%|          | 32/50000 [00:18<7:24:19,  1.87it/s]/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Extracting features from test files:   0%|          | 184/50000 [01:47<9:18:38,  1.49it/s] /var/folders/qn/7th_wqcj195_4h1jz82g618m0000gn/T/ipykernel_74159/3285360863.py:55: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  skew(features, axis=0),\n",
      "/var/folders/qn/7th_wqcj195_4h1jz82g618m0000gn/T/ipykernel_74159/3285360863.py:56: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  kurtosis(features, axis=0)\n",
      "Extracting features from test files: 100%|██████████| 50000/50000 [8:13:09<00:00,  1.69it/s]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import wiener\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    ROOT_FOLDER = './'\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 32\n",
    "    N_EPOCHS = 50\n",
    "    LR = 3e-4\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "def pad_or_truncate(audio, target_length):\n",
    "    if len(audio) > target_length:\n",
    "        return audio[:target_length]\n",
    "    else:\n",
    "        return np.pad(audio, (0, target_length - len(audio)), mode='reflect')\n",
    "\n",
    "def preemphasis(signal, coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "def noise_reduction(signal):\n",
    "    filtered_signal = wiener(signal)\n",
    "    return filtered_signal / np.sqrt(np.mean(filtered_signal ** 2))  # RMS 정규화\n",
    "\n",
    "def energy_vad(signal, frame_length=2048, hop_length=512, threshold=0.1):\n",
    "    energy = librosa.feature.rms(y=signal, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    frames = np.nonzero(energy > threshold)[0]\n",
    "    vad_signal = []\n",
    "    for frame in frames:\n",
    "        start = frame * hop_length\n",
    "        end = start + frame_length\n",
    "        vad_signal.extend(signal[start:end])\n",
    "    return np.array(vad_signal)\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    return np.concatenate([\n",
    "        np.mean(features, axis=0),\n",
    "        np.std(features, axis=0),\n",
    "        np.max(features, axis=0),\n",
    "        np.min(features, axis=0),\n",
    "        np.median(features, axis=0),\n",
    "        np.percentile(features, 25, axis=0),\n",
    "        np.percentile(features, 75, axis=0),\n",
    "        skew(features, axis=0),\n",
    "        kurtosis(features, axis=0)\n",
    "    ])\n",
    "\n",
    "def extract_features(audio_path, target_length=5*CONFIG.SR):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=CONFIG.SR)\n",
    "        sr = CONFIG.SR\n",
    "\n",
    "        y = preemphasis(y)\n",
    "        y = noise_reduction(y)\n",
    "\n",
    "        vad_signal = energy_vad(y)\n",
    "\n",
    "        if len(vad_signal) == 0:\n",
    "            vad_signal = y\n",
    "\n",
    "        vad_signal = pad_or_truncate(vad_signal, target_length)\n",
    "        mfcc = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc2 = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=2 * CONFIG.N_MFCC)\n",
    "        stft = np.abs(librosa.stft(vad_signal))\n",
    "        chroma = librosa.feature.chroma_stft(y=vad_signal, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=vad_signal, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(vad_signal), sr=sr)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        return np.concatenate([\n",
    "            calculate_statistics(mfcc.T),\n",
    "            calculate_statistics(mfcc2.T),\n",
    "            calculate_statistics(stft.T),\n",
    "            calculate_statistics(chroma.T),\n",
    "            calculate_statistics(spectral_contrast.T),\n",
    "            calculate_statistics(tonnetz.T),\n",
    "            calculate_statistics(mfcc_delta.T),\n",
    "            calculate_statistics(mfcc_delta2.T)\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return np.zeros((CONFIG.N_MFCC * 9 + 2 * CONFIG.N_MFCC * 9 + 1025 * 9 + 12 * 9 + 7 * 9 + 6 * 9 + CONFIG.N_MFCC * 9 + CONFIG.N_MFCC * 9))\n",
    "\n",
    "# 모델 불러오기\n",
    "with open('./newFolder/rf_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# test.csv 파일 읽기\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# test.csv 파일에 있는 모든 파일에 대해 특징 추출 및 예측 수행\n",
    "test_features = []\n",
    "file_ids = []\n",
    "\n",
    "for file_id in tqdm(test_df['id'], desc=\"Extracting features from test files\"):\n",
    "    file_path = os.path.join('./test', file_id + '.ogg')\n",
    "    features = extract_features(file_path)\n",
    "    test_features.append(features)\n",
    "    file_ids.append(file_id)\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "# NaN 값을 평균값으로 대체\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "test_features = imputer.fit_transform(test_features)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_proba = rf_model.predict_proba(test_features)\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "results = pd.DataFrame({\n",
    "    'id': file_ids,\n",
    "    'fake': [prob[1] for prob in y_pred_proba[0]],\n",
    "    'real': [prob[1] for prob in y_pred_proba[1]]\n",
    "})\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spleeter\n",
      "  Downloading spleeter-2.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ffmpeg-python<0.3.0,>=0.2.0 (from spleeter)\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting httpx<0.20.0,>=0.19.0 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading httpx-0.19.0-py3-none-any.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting norbert<0.3.0,>=0.2.1 (from spleeter)\n",
      "  Downloading norbert-0.2.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pandas<2.0.0,>=1.3.0 (from spleeter)\n",
      "  Downloading pandas-1.5.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of spleeter to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting spleeter\n",
      "  Downloading spleeter-2.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting librosa<0.9.0,>=0.8.0 (from spleeter)\n",
      "  Downloading librosa-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting llvmlite<0.39.0,>=0.38.0 (from spleeter)\n",
      "  Downloading llvmlite-0.38.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.2 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from spleeter) (1.24.4)\n",
      "Collecting protobuf<4.0.0,>=3.19.4 (from spleeter)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting tensorflow<3.0.0,>=2.5.0 (from spleeter)\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting typer<0.4.0,>=0.3.2 (from spleeter)\n",
      "  Downloading typer-0.3.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting future (from ffmpeg-python<0.3.0,>=0.2.0->spleeter)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: scipy in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from norbert<0.3.0,>=0.2.1->spleeter) (1.10.1)\n",
      "Requirement already satisfied: certifi in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.3.2)\n",
      "Requirement already satisfied: sniffio in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.3.1)\n",
      "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore<0.14.0,>=0.13.3 (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading httpcore-0.13.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.4.2)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (5.1.1)\n",
      "Collecting resampy>=0.2.2 (from librosa<0.9.0,>=0.8.0->spleeter)\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numba>=0.43.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from librosa<0.9.0,>=0.8.0->spleeter) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2024.1)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow<3.0.0,>=2.5.0 (from spleeter)\n",
      "  Downloading tensorflow-2.13.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-macos==2.13.0 (from tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading tensorflow_macos-2.13.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading h5py-3.11.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting numpy<2.0.0,>=1.19.2 (from spleeter)\n",
      "  Downloading numpy-1.24.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: setuptools in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading grpcio-1.64.1-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting click<7.2.0,>=7.1.1 (from typer<0.4.0,>=0.3.2->spleeter)\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting h11<0.13,>=0.11 (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading h11-0.12.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting anyio==3.* (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.1)\n",
      "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numba>=0.43.0 (from librosa<0.9.0,>=0.8.0->spleeter)\n",
      "  Downloading numba-0.58.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "  Downloading numba-0.57.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "  Downloading numba-0.57.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "  Downloading numba-0.56.4-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "  Downloading numba-0.56.3-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "  Downloading numba-0.56.2-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "  Downloading numba-0.56.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "INFO: pip is still looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading numba-0.55.2-cp38-cp38-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting numpy<2.0.0,>=1.19.2 (from spleeter)\n",
      "  Downloading numpy-1.22.4-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (2.32.3)\n",
      "Requirement already satisfied: importlib-resources in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from resampy>=0.2.2->librosa<0.9.0,>=0.8.0->spleeter) (6.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.9.0,>=0.8.0->spleeter) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (1.16.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pycparser in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (2.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (2.2.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from importlib-resources->resampy>=0.2.2->librosa<0.9.0,>=0.8.0->spleeter) (3.19.2)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter) (2.1.5)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow<3.0.0,>=2.5.0->spleeter)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading spleeter-2.3.2-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.38.1-cp38-cp38-macosx_11_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp38-cp38-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.0-cp38-cp38-macosx_12_0_arm64.whl (1.9 kB)\n",
      "Downloading tensorflow_macos-2.13.0-cp38-cp38-macosx_12_0_arm64.whl (189.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.55.2-cp38-cp38-macosx_11_0_arm64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.22.4-cp38-cp38-macosx_11_0_arm64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.64.1-cp38-cp38-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp38-cp38-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading wrapt-1.16.0-cp38-cp38-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rfc3986, libclang, flatbuffers, wrapt, wheel, werkzeug, typing-extensions, termcolor, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, llvmlite, keras, hyperframe, hpack, h11, grpcio, google-pasta, gast, future, click, cachetools, anyio, absl-py, typer, rsa, requests-oauthlib, pyasn1-modules, pandas, opt-einsum, numba, markdown, httpcore, h5py, h2, ffmpeg-python, astunparse, resampy, norbert, httpx, google-auth, librosa, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow, spleeter\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.41.1\n",
      "    Uninstalling llvmlite-0.41.1:\n",
      "      Successfully uninstalled llvmlite-0.41.1\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.58.1\n",
      "    Uninstalling numba-0.58.1:\n",
      "      Successfully uninstalled numba-0.58.1\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.2.post1\n",
      "    Uninstalling librosa-0.10.2.post1:\n",
      "      Successfully uninstalled librosa-0.10.2.post1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.2.2 requires httpx>=0.25.0, but you have httpx 0.19.0 which is incompatible.\n",
      "torch 2.3.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 anyio-3.7.1 astunparse-1.6.3 cachetools-5.3.3 click-7.1.2 ffmpeg-python-0.2.0 flatbuffers-24.3.25 future-1.0.0 gast-0.4.0 google-auth-2.32.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.64.1 h11-0.12.0 h2-4.1.0 h5py-3.11.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 keras-2.13.1 libclang-18.1.1 librosa-0.8.1 llvmlite-0.38.1 markdown-3.6 norbert-0.2.1 numba-0.55.2 numpy-1.22.4 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-1.5.3 protobuf-3.20.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-oauthlib-2.0.0 resampy-0.4.3 rfc3986-1.5.0 rsa-4.9 spleeter-2.3.2 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-macos-2.13.0 termcolor-2.4.0 typer-0.3.2 typing-extensions-4.5.0 werkzeug-3.0.3 wheel-0.43.0 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spleeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unlabeled data labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from unlabeled files:   0%|          | 4/1264 [00:02<12:26,  1.69it/s]/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/pitch.py:153: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn(\"Trying to estimate tuning from empty frequency set.\")\n",
      "Extracting features from unlabeled files:   2%|▏         | 19/1264 [00:11<11:50,  1.75it/s]/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/scipy/signal/_signaltools.py:1629: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  res *= (1 - noise / lVar)\n",
      "/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/scipy/signal/_signaltools.py:1629: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n",
      "Extracting features from unlabeled files: 100%|██████████| 1264/1264 [11:32<00:00,  1.83it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 122\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m# 예측 수행\u001b[39;00m\n\u001b[1;32m    121\u001b[0m y_pred_proba \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict_proba(test_features)\n\u001b[0;32m--> 122\u001b[0m y_pred \u001b[39m=\u001b[39m (y_pred_proba[:, \u001b[39m1\u001b[39;49m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)  \u001b[39m# 진짜 목소리일 확률이 높으면 1, 가짜 목소리일 확률이 높으면 0\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# 예측 결과를 DataFrame으로 저장\u001b[39;00m\n\u001b[1;32m    125\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m    126\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m: file_paths,\n\u001b[1;32m    127\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: y_pred\n\u001b[1;32m    128\u001b[0m })\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import wiener\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    ROOT_FOLDER = './'\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 32\n",
    "    N_EPOCHS = 50\n",
    "    LR = 3e-4\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "def pad_or_truncate(audio, target_length):\n",
    "    if len(audio) > target_length:\n",
    "        return audio[:target_length]\n",
    "    else:\n",
    "        return np.pad(audio, (0, target_length - len(audio)), mode='reflect')\n",
    "\n",
    "def preemphasis(signal, coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "def noise_reduction(signal):\n",
    "    filtered_signal = wiener(signal)\n",
    "    return filtered_signal / np.sqrt(np.mean(filtered_signal ** 2))  # RMS 정규화\n",
    "\n",
    "def energy_vad(signal, frame_length=2048, hop_length=512, threshold=0.1):\n",
    "    energy = librosa.feature.rms(y=signal, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    frames = np.nonzero(energy > threshold)[0]\n",
    "    vad_signal = []\n",
    "    for frame in frames:\n",
    "        start = frame * hop_length\n",
    "        end = start + frame_length\n",
    "        vad_signal.extend(signal[start:end])\n",
    "    return np.array(vad_signal)\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    return np.concatenate([\n",
    "        np.mean(features, axis=0),\n",
    "        np.std(features, axis=0),\n",
    "        np.max(features, axis=0),\n",
    "        np.min(features, axis=0),\n",
    "        np.median(features, axis=0),\n",
    "        np.percentile(features, 25, axis=0),\n",
    "        np.percentile(features, 75, axis=0),\n",
    "        skew(features, axis=0),\n",
    "        kurtosis(features, axis=0)\n",
    "    ])\n",
    "\n",
    "def extract_features(audio_path, target_length=5*CONFIG.SR):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=None)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=CONFIG.SR)\n",
    "        sr = CONFIG.SR\n",
    "\n",
    "        y = preemphasis(y)\n",
    "        y = noise_reduction(y)\n",
    "\n",
    "        vad_signal = energy_vad(y)\n",
    "\n",
    "        if len(vad_signal) == 0:\n",
    "            vad_signal = y\n",
    "\n",
    "        vad_signal = pad_or_truncate(vad_signal, target_length)\n",
    "        mfcc = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc2 = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=2 * CONFIG.N_MFCC)\n",
    "        stft = np.abs(librosa.stft(vad_signal))\n",
    "        chroma = librosa.feature.chroma_stft(y=vad_signal, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=vad_signal, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(vad_signal), sr=sr)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        return np.concatenate([\n",
    "            calculate_statistics(mfcc.T),\n",
    "            calculate_statistics(mfcc2.T),\n",
    "            calculate_statistics(stft.T),\n",
    "            calculate_statistics(chroma.T),\n",
    "            calculate_statistics(spectral_contrast.T),\n",
    "            calculate_statistics(tonnetz.T),\n",
    "            calculate_statistics(mfcc_delta.T),\n",
    "            calculate_statistics(mfcc_delta2.T)\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return np.zeros((CONFIG.N_MFCC * 9 + 2 * CONFIG.N_MFCC * 9 + 1025 * 9 + 12 * 9 + 7 * 9 + 6 * 9 + CONFIG.N_MFCC * 9 + CONFIG.N_MFCC * 9))\n",
    "\n",
    "# 모델 불러오기\n",
    "with open('./newFolder/rf_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# unlabeled_data 폴더 내 모든 파일 처리\n",
    "unlabeled_folder = './unlabeled_data'\n",
    "audio_files = [f for f in os.listdir(unlabeled_folder) if os.path.isfile(os.path.join(unlabeled_folder, f))]\n",
    "\n",
    "test_features = []\n",
    "file_paths = []\n",
    "\n",
    "for audio_file in tqdm(audio_files, desc=\"Extracting features from unlabeled files\"):\n",
    "    file_path = os.path.join(unlabeled_folder, audio_file)\n",
    "    features = extract_features(file_path)\n",
    "    test_features.append(features)\n",
    "    file_paths.append(file_path)\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "# NaN 값을 평균값으로 대체\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "test_features = imputer.fit_transform(test_features)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_proba = rf_model.predict_proba(test_features)\n",
    "y_pred = (y_pred_proba[:, 1] >= 0.5).astype(int)  # 진짜 목소리일 확률이 높으면 1, 가짜 목소리일 확률이 높으면 0\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "results = pd.DataFrame({\n",
    "    'path': file_paths,\n",
    "    'label': y_pred\n",
    "})\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results.to_csv('unlabeled_data_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from test files:   0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "WARNING:tensorflow:From /Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:spleeter:Downloading model archive https://github.com/deezer/spleeter/releases/download/v1.4.0/2stems.tar.gz\n",
      "INFO:spleeter:Validating archive checksum\n",
      "INFO:spleeter:Extracting downloaded 2stems archive\n",
      "INFO:spleeter:2stems model file(s) extracted\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songseungju/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "Extracting features from test files:   0%|          | 0/50000 [00:28<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File ./output/TEST_00000/accompaniment.wav written succesfully\n",
      "INFO:spleeter:File ./output/TEST_00000/vocals.wav written succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/vocals.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/audio.py:149\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mwith\u001b[39;00m sf\u001b[39m.\u001b[39;49mSoundFile(path) \u001b[39mas\u001b[39;00m sf_desc:\n\u001b[1;32m    150\u001b[0m         sr_native \u001b[39m=\u001b[39m sf_desc\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening './output/vocals.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m./test\u001b[39m\u001b[39m'\u001b[39m, file_id \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.ogg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m vocal_path, accompaniment_path \u001b[39m=\u001b[39m separate_voices(file_path)\n\u001b[0;32m--> 118\u001b[0m y_vocal, sr_vocal \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(vocal_path, sr\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    119\u001b[0m y_accompaniment, sr_accompaniment \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(accompaniment_path, sr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    121\u001b[0m features_vocal \u001b[39m=\u001b[39m extract_features(y_vocal, sr_vocal)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/audio.py:166\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    165\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[39mraise\u001b[39;00m (exc)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/librosa/core/audio.py:190\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an audio buffer using audioread.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[39mThis loads one block at a time, and then concatenates the results.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m y \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m audioread\u001b[39m.\u001b[39;49maudio_open(path) \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    191\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n\u001b[1;32m    192\u001b[0m     n_channels \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39mchannels\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.18/envs/.venv/lib/python3.8/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/vocals.wav'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import wiener\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.impute import SimpleImputer\n",
    "from spleeter.separator import Separator\n",
    "\n",
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    ROOT_FOLDER = './'\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 32\n",
    "    N_EPOCHS = 50\n",
    "    LR = 3e-4\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "def pad_or_truncate(audio, target_length):\n",
    "    if len(audio) > target_length:\n",
    "        return audio[:target_length]\n",
    "    else:\n",
    "        return np.pad(audio, (0, target_length - len(audio)), mode='reflect')\n",
    "\n",
    "def preemphasis(signal, coeff=0.97):\n",
    "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "def noise_reduction(signal):\n",
    "    filtered_signal = wiener(signal)\n",
    "    return filtered_signal / np.sqrt(np.mean(filtered_signal ** 2))  # RMS 정규화\n",
    "\n",
    "def energy_vad(signal, frame_length=2048, hop_length=512, threshold=0.1):\n",
    "    energy = librosa.feature.rms(y=signal, frame_length=frame_length, hop_length=hop_length)[0]\n",
    "    frames = np.nonzero(energy > threshold)[0]\n",
    "    vad_signal = []\n",
    "    for frame in frames:\n",
    "        start = frame * hop_length\n",
    "        end = start + frame_length\n",
    "        vad_signal.extend(signal[start:end])\n",
    "    return np.array(vad_signal)\n",
    "\n",
    "def calculate_statistics(features):\n",
    "    return np.concatenate([\n",
    "        np.mean(features, axis=0),\n",
    "        np.std(features, axis=0),\n",
    "        np.max(features, axis=0),\n",
    "        np.min(features, axis=0),\n",
    "        np.median(features, axis=0),\n",
    "        np.percentile(features, 25, axis=0),\n",
    "        np.percentile(features, 75, axis=0),\n",
    "        skew(features, axis=0),\n",
    "        kurtosis(features, axis=0)\n",
    "    ])\n",
    "\n",
    "def extract_features(y, sr, target_length=5*CONFIG.SR):\n",
    "    try:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=CONFIG.SR)\n",
    "        sr = CONFIG.SR\n",
    "\n",
    "        y = preemphasis(y)\n",
    "        y = noise_reduction(y)\n",
    "\n",
    "        vad_signal = energy_vad(y)\n",
    "\n",
    "        if len(vad_signal) == 0:\n",
    "            vad_signal = y\n",
    "\n",
    "        vad_signal = pad_or_truncate(vad_signal, target_length)\n",
    "        mfcc = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc2 = librosa.feature.mfcc(y=vad_signal, sr=sr, n_mfcc=2 * CONFIG.N_MFCC)\n",
    "        stft = np.abs(librosa.stft(vad_signal))\n",
    "        chroma = librosa.feature.chroma_stft(y=vad_signal, sr=sr)\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=vad_signal, sr=sr)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(vad_signal), sr=sr)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        return np.concatenate([\n",
    "            calculate_statistics(mfcc.T),\n",
    "            calculate_statistics(mfcc2.T),\n",
    "            calculate_statistics(stft.T),\n",
    "            calculate_statistics(chroma.T),\n",
    "            calculate_statistics(spectral_contrast.T),\n",
    "            calculate_statistics(tonnetz.T),\n",
    "            calculate_statistics(mfcc_delta.T),\n",
    "            calculate_statistics(mfcc_delta2.T)\n",
    "        ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {e}\")\n",
    "        return np.zeros((CONFIG.N_MFCC * 9 + 2 * CONFIG.N_MFCC * 9 + 1025 * 9 + 12 * 9 + 7 * 9 + 6 * 9 + CONFIG.N_MFCC * 9 + CONFIG.N_MFCC * 9))\n",
    "\n",
    "def separate_voices(audio_path):\n",
    "    separator = Separator('spleeter:2stems')\n",
    "    output_dir = './output'\n",
    "    separator.separate_to_file(audio_path, output_dir)\n",
    "    return os.path.join(output_dir, 'vocals.wav'), os.path.join(output_dir, 'accompaniment.wav')\n",
    "\n",
    "# 모델 불러오기\n",
    "with open('./newFolder/rf_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "# test.csv 파일 읽기\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# test.csv 파일에 있는 모든 파일에 대해 특징 추출 및 예측 수행\n",
    "test_features = []\n",
    "file_ids = []\n",
    "\n",
    "for file_id in tqdm(test_df['id'], desc=\"Extracting features from test files\"):\n",
    "    file_path = os.path.join('./test', file_id + '.ogg')\n",
    "    vocal_path, accompaniment_path = separate_voices(file_path)\n",
    "    \n",
    "    y_vocal, sr_vocal = librosa.load(vocal_path, sr=None)\n",
    "    y_accompaniment, sr_accompaniment = librosa.load(accompaniment_path, sr=None)\n",
    "    \n",
    "    features_vocal = extract_features(y_vocal, sr_vocal)\n",
    "    features_accompaniment = extract_features(y_accompaniment, sr_accompaniment)\n",
    "    \n",
    "    combined_features = np.concatenate([features_vocal, features_accompaniment])\n",
    "    test_features.append(combined_features)\n",
    "    file_ids.append(file_id)\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "# NaN 값을 평균값으로 대체\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "test_features = imputer.fit_transform(test_features)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred_proba = rf_model.predict_proba(test_features)\n",
    "\n",
    "# 예측 결과를 DataFrame으로 저장\n",
    "results = pd.DataFrame({\n",
    "    'id': file_ids,\n",
    "    'fake': [prob[1] for prob in y_pred_proba[:, 0]],\n",
    "    'real': [prob[1] for prob in y_pred_proba[:, 1]]\n",
    "})\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 64-bit ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a191662cde2ebcb42f83a2adeea8d5655c1ecddbab08541ee02f9db5d6a4e26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
